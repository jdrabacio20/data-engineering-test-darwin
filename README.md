# Data Engineering Assessment

## Introduction
This project is a data engineering assessment aimed at demonstrating proficiency in data processing and ETL (Extract, Transform, Load) using Python.

## Objective
The purpose of this task is to construct a data pipeline that:
1. Ingests data from a publicly available dataset.
2. Cleanses and validates the data.
3. Applies transformations, including standardizing dates and performing aggregations.
4. Loads the transformed data into a mock data warehouse (CSV file or SQLite database).

## Dataset
The pipeline will utilize a sample dataset generated in Python, covering data from the previous year up to the current date. The dataset includes fields such as [date, sales, category, etc.].

## Requirements
- Python-based ETL pipeline.
- Data validation mechanisms.
- Data transformations (e.g., date formatting, data aggregation).
- Loading of the transformed data to a structured format (CSV or SQLite).
- Unit tests to ensure functionality.
- Comprehensive documentation and code comments.
